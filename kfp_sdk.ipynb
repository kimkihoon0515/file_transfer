{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263158f8-d7ef-4382-91ae-4a1844e424ca",
   "metadata": {},
   "source": [
    "# Client 동기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f7436d5e-fe19-4509-b2de-fdf5f2fc776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import requests\n",
    "\n",
    "USERNAME = \"user@example.com\"\n",
    "PASSWORD = \"12341234\"\n",
    "NAMESPACE = \"kubeflow-user-example-com\"\n",
    "HOST = \"http://127.0.0.1:8080\" # istio-ingressgateway pod ip:port\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.get(HOST)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "}\n",
    "\n",
    "data = {\"login\": \"user@example.com\", \"password\": \"12341234\"}\n",
    "session.post(response.url, headers=headers, data=data)\n",
    "session_cookie = session.cookies.get_dict()[\"authservice_session\"]\n",
    "\n",
    "client = kfp.Client(\n",
    "    host=f\"{HOST}/pipeline\",\n",
    "    namespace=f\"{NAMESPACE}\",\n",
    "    cookies=f\"authservice_session={session_cookie}\",\n",
    ")\n",
    "list_pipelines = client.list_pipelines()\n",
    "\n",
    "print(list_pipelines.total_size)\n",
    "\n",
    "#for i in range(list_pipelines.total_size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baae55e2-c478-4428-ae7c-99a77175b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kfp._client.Client at 0x1044ee910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594aae4-6ae0-48ba-8fe4-0081e94adf8d",
   "metadata": {},
   "source": [
    "## Pipeline Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9411a88b-fb8b-4529-90b0-6fdbc7fe19b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=http://127.0.0.1:8080/pipeline/#/pipelines/details/717a9a42-bdd0-4aee-868d-b95a663994d8>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 1, 9, 13, 53, 57, tzinfo=tzutc()),\n",
       " 'default_version': {'code_source_url': None,\n",
       "                     'created_at': datetime.datetime(2023, 1, 9, 13, 53, 57, tzinfo=tzutc()),\n",
       "                     'description': None,\n",
       "                     'id': '717a9a42-bdd0-4aee-868d-b95a663994d8',\n",
       "                     'name': 'torch',\n",
       "                     'package_url': None,\n",
       "                     'parameters': None,\n",
       "                     'resource_references': [{'key': {'id': '717a9a42-bdd0-4aee-868d-b95a663994d8',\n",
       "                                                      'type': 'PIPELINE'},\n",
       "                                              'name': None,\n",
       "                                              'relationship': 'OWNER'}]},\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'id': '717a9a42-bdd0-4aee-868d-b95a663994d8',\n",
       " 'name': 'torch',\n",
       " 'parameters': None,\n",
       " 'resource_references': None,\n",
       " 'url': None}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_package_path='/Users/gimgihun/file_transfer/practice/test.yaml'\n",
    "pipeline_name='torch'\n",
    "client.upload_pipeline(pipeline_package_path=pipeline_package_path,pipeline_name=pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e7bde-452b-4df3-9e45-597d05fb7a44",
   "metadata": {},
   "source": [
    "# Experiment 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "45150325-3463-4273-8d04-72f1e125c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://127.0.0.1:8080/pipeline/#/experiments/details/27dedf49-c92b-4124-b3ee-90745922498d\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = client.create_experiment(name=pipeline_name,description=pipeline_name,namespace=NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f2845b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27dedf49-c92b-4124-b3ee-90745922498d'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_info = client.get_experiment(experiment_name=pipeline_name,namespace=NAMESPACE)\n",
    "experiment_id = experiment_info.id\n",
    "experiment_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1725b41-9866-4760-aef2-3dfef09689cc",
   "metadata": {},
   "source": [
    "## Run 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "35fe5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://127.0.0.1:8080/pipeline/#/runs/details/198b0ea4-a80c-45e6-a19d-e6610f0dd883\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 1, 9, 13, 53, 59, tzinfo=tzutc()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzutc()),\n",
       " 'id': '198b0ea4-a80c-45e6-a19d-e6610f0dd883',\n",
       " 'metrics': None,\n",
       " 'name': 'torch',\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': None,\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': None,\n",
       "                   'runtime_config': None,\n",
       "                   'workflow_manifest': '{\"apiVersion\": '\n",
       "                                        '\"argoproj.io/v1alpha1\", \"kind\": '\n",
       "                                        '\"Workflow\", \"metadata\": '\n",
       "                                        '{\"generateName\": '\n",
       "                                        '\"practice-pipeline-\", \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.8.18\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline_compilation_time\": '\n",
       "                                        '\"2023-01-09T22:53:49.449145\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline_spec\": '\n",
       "                                        '\"{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"practice-pipeline\\\\\"}\"}, \"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.8.18\"}}, \"spec\": {\"entrypoint\": '\n",
       "                                        '\"practice-pipeline\", \"templates\": '\n",
       "                                        '[{\"name\": \"download-dataset\", '\n",
       "                                        '\"container\": {\"args\": [], \"command\": '\n",
       "                                        '[\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def download_dataset(): \\\\n    from '\n",
       "                                        'torchvision import datasets\\\\n    '\n",
       "                                        'from torchvision import '\n",
       "                                        'transforms\\\\n    from '\n",
       "                                        'torch.utils.data import '\n",
       "                                        'DataLoader\\\\n    import os\\\\n    '\n",
       "                                        \"download_root = '/MNIST_data/' \"\n",
       "                                        '\\\\n\\\\n    train_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\n                            '\n",
       "                                        'train=True,\\\\n                            '\n",
       "                                        'transform=transforms.ToTensor(),\\\\n                            '\n",
       "                                        'download=True) \\\\n\\\\n    test_dataset '\n",
       "                                        '= '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\n                            '\n",
       "                                        'train=False,\\\\n                            '\n",
       "                                        'transform=transforms.ToTensor(), '\n",
       "                                        '\\\\n                            '\n",
       "                                        'download=True) \\\\n\\\\n    batch_size = '\n",
       "                                        '100 \\\\n\\\\nimport argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Download \"\n",
       "                                        \"dataset', \"\n",
       "                                        \"description='')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'download_dataset(**_parsed_args)\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-pytorch:v1.5.0\"}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.8.18\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\", '\n",
       "                                        '\"pipelines.kubeflow.org/enable_caching\": '\n",
       "                                        '\"true\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": [], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'download_dataset(): \\\\\\\\n    from '\n",
       "                                        'torchvision import datasets\\\\\\\\n    '\n",
       "                                        'from torchvision import '\n",
       "                                        'transforms\\\\\\\\n    from '\n",
       "                                        'torch.utils.data import '\n",
       "                                        'DataLoader\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        \"download_root = '/MNIST_data/' \"\n",
       "                                        '\\\\\\\\n\\\\\\\\n    train_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\\\\\n                            '\n",
       "                                        'train=True,\\\\\\\\n                            '\n",
       "                                        'transform=transforms.ToTensor(),\\\\\\\\n                            '\n",
       "                                        'download=True) \\\\\\\\n\\\\\\\\n    '\n",
       "                                        'test_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\\\\\n                            '\n",
       "                                        'train=False,\\\\\\\\n                            '\n",
       "                                        'transform=transforms.ToTensor(), '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'download=True) \\\\\\\\n\\\\\\\\n    '\n",
       "                                        'batch_size = 100 \\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Download \"\n",
       "                                        \"dataset', \"\n",
       "                                        \"description='')\\\\\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'download_dataset(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-pytorch:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Download dataset\\\\\"}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\"}}}, {\"name\": '\n",
       "                                        '\"practice-pipeline\", \"dag\": {\"tasks\": '\n",
       "                                        '[{\"name\": \"download-dataset\", '\n",
       "                                        '\"template\": \"download-dataset\"}, '\n",
       "                                        '{\"name\": \"train\", \"template\": '\n",
       "                                        '\"train\", \"dependencies\": '\n",
       "                                        '[\"download-dataset\"]}]}}, {\"name\": '\n",
       "                                        '\"train\", \"container\": {\"args\": [], '\n",
       "                                        '\"command\": [\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def train():\\\\n  import torch.nn as '\n",
       "                                        'nn\\\\n  import torch\\\\n  from '\n",
       "                                        'torchvision import datasets\\\\n  from '\n",
       "                                        'torchvision import transforms\\\\n  '\n",
       "                                        'from torch.utils.data import '\n",
       "                                        'DataLoader\\\\n  import numpy as np\\\\n  '\n",
       "                                        'import json\\\\n  import os\\\\n\\\\n  '\n",
       "                                        'class Net(nn.Module): \\\\n\\\\n      def '\n",
       "                                        '__init__(self):\\\\n          '\n",
       "                                        'super(Net, '\n",
       "                                        'self).__init__()\\\\n          self.fc1 '\n",
       "                                        '= nn.Linear(784,100) \\\\n          '\n",
       "                                        'self.relu = nn.ReLU()\\\\n          '\n",
       "                                        'self.fc2 = nn.Linear(100,100) '\n",
       "                                        '\\\\n          self.fc3 = '\n",
       "                                        'nn.Linear(100,10) \\\\n\\\\n      def '\n",
       "                                        'forward(self, x): \\\\n          x1 = '\n",
       "                                        'self.fc1(x)\\\\n          x2 = '\n",
       "                                        'self.relu(x1)\\\\n          x3 = '\n",
       "                                        'self.fc2(x2)\\\\n          x4 = '\n",
       "                                        'self.relu(x3)\\\\n          x5 = '\n",
       "                                        'self.fc3(x4)\\\\n\\\\n          return '\n",
       "                                        'x5\\\\n\\\\n  download_root = '\n",
       "                                        \"'./MNIST_data'\\\\n\\\\n  train_dataset = \"\n",
       "                                        'datasets.MNIST(root=download_root,\\\\n                          '\n",
       "                                        'train=True,\\\\n                          '\n",
       "                                        'transform=transforms.ToTensor(),\\\\n                          '\n",
       "                                        'download=True) \\\\n\\\\n  test_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\n                          '\n",
       "                                        'train=False,\\\\n                          '\n",
       "                                        'transform=transforms.ToTensor(), '\n",
       "                                        '\\\\n                          '\n",
       "                                        'download=True) \\\\n\\\\n  batch_size = '\n",
       "                                        '100\\\\n  train_loader = '\n",
       "                                        'DataLoader(train_dataset, '\n",
       "                                        'batch_size=batch_size, '\n",
       "                                        'shuffle=True)\\\\n  test_loader = '\n",
       "                                        'DataLoader(test_dataset, '\n",
       "                                        'batch_size=batch_size, shuffle=True) '\n",
       "                                        '\\\\n\\\\n  model = Net() \\\\n  '\n",
       "                                        'loss_function = nn.CrossEntropyLoss() '\n",
       "                                        '\\\\n\\\\n  optimizer = '\n",
       "                                        'torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\\\\n  '\n",
       "                                        'epochs = 1\\\\n\\\\n  best_accuracy = '\n",
       "                                        '0\\\\n  model.zero_grad() \\\\n\\\\n  for '\n",
       "                                        'epoch in range(epochs):\\\\n\\\\n    '\n",
       "                                        'model.train() \\\\n    train_accuracy = '\n",
       "                                        '0 \\\\n    train_loss = 0 \\\\n\\\\n    for '\n",
       "                                        'images, labels in '\n",
       "                                        'train_loader:\\\\n      images = '\n",
       "                                        'images.reshape(batch_size,784)\\\\n      '\n",
       "                                        'image = model(images)\\\\n      loss = '\n",
       "                                        'loss_function(image,labels)\\\\n\\\\n      '\n",
       "                                        'optimizer.zero_grad()\\\\n      '\n",
       "                                        'loss.backward()\\\\n      '\n",
       "                                        'optimizer.step()\\\\n\\\\n      '\n",
       "                                        'prediction = '\n",
       "                                        'torch.argmax(image,1)\\\\n      correct '\n",
       "                                        '= (prediction == labels)\\\\n      '\n",
       "                                        'train_accuracy+= correct.sum().item() '\n",
       "                                        '/ len(train_dataset)\\\\n      '\n",
       "                                        'train_loss += loss.item() / '\n",
       "                                        'len(train_loader)\\\\n\\\\n    '\n",
       "                                        'model.eval() \\\\n    val_accuracy = 0 '\n",
       "                                        '\\\\n    val_loss = 0 \\\\n\\\\n    for '\n",
       "                                        'images,labels in test_loader:\\\\n      '\n",
       "                                        'images = '\n",
       "                                        'images.reshape(batch_size,784)\\\\n      '\n",
       "                                        'image = model(images)\\\\n      loss = '\n",
       "                                        'loss_function(image,labels)\\\\n\\\\n      '\n",
       "                                        'correct = (torch.argmax(image,1) == '\n",
       "                                        'labels)\\\\n      val_accuracy += '\n",
       "                                        'correct.sum().item() / '\n",
       "                                        'len(test_dataset)\\\\n      val_loss += '\n",
       "                                        'loss.item() / '\n",
       "                                        'len(test_loader)\\\\n\\\\n    '\n",
       "                                        \"print(f'epoch: {epoch}/{epochs} \"\n",
       "                                        'train_loss: {train_loss:.5} '\n",
       "                                        'train_accuracy: {train_accuracy:.5} '\n",
       "                                        'val_loss: {val_loss:.5} val_accuracy: '\n",
       "                                        \"{val_accuracy:.5}')\\\\n\\\\n    if \"\n",
       "                                        'best_accuracy < val_accuracy: '\n",
       "                                        '\\\\n      best_accuracy = '\n",
       "                                        'val_accuracy\\\\n      best_val_loss = '\n",
       "                                        'val_loss\\\\n      '\n",
       "                                        \"torch.save(model.state_dict(),'./best_model.pt')\\\\n      \"\n",
       "                                        'print(f\\\\\"===========> Save '\n",
       "                                        'Model(Epoch: {epoch}, Accuracy: '\n",
       "                                        '{best_accuracy:.5})\\\\\")\\\\n\\\\n    '\n",
       "                                        'print(\\\\\"--------------------------------------------------------------------------------------------\\\\\")\\\\n\\\\n  '\n",
       "                                        \"metrics = {\\\\n        'metrics': \"\n",
       "                                        \"[{\\\\n            'name': \"\n",
       "                                        \"'accuracy-score',\\\\n            \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'best_accuracy,\\\\n            '\n",
       "                                        \"'format': \"\n",
       "                                        '\\\\\"PERCENTAGE\\\\\",\\\\n        }]\\\\n    '\n",
       "                                        '}\\\\n\\\\n  with '\n",
       "                                        \"open('./mlpipeline-metrics.json','w') \"\n",
       "                                        'as f:\\\\n    '\n",
       "                                        'json.dump(metrics,f)\\\\n\\\\n  '\n",
       "                                        'print(\\\\\"best_model uploaded to '\n",
       "                                        'pvc!\\\\\")\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train', \"\n",
       "                                        \"description='')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= train(**_parsed_args)\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-pytorch:v1.5.0\"}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.8.18\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\", '\n",
       "                                        '\"pipelines.kubeflow.org/enable_caching\": '\n",
       "                                        '\"true\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": [], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'train():\\\\\\\\n  import torch.nn as '\n",
       "                                        'nn\\\\\\\\n  import torch\\\\\\\\n  from '\n",
       "                                        'torchvision import datasets\\\\\\\\n  '\n",
       "                                        'from torchvision import '\n",
       "                                        'transforms\\\\\\\\n  from '\n",
       "                                        'torch.utils.data import '\n",
       "                                        'DataLoader\\\\\\\\n  import numpy as '\n",
       "                                        'np\\\\\\\\n  import json\\\\\\\\n  import '\n",
       "                                        'os\\\\\\\\n\\\\\\\\n  class Net(nn.Module): '\n",
       "                                        '\\\\\\\\n\\\\\\\\n      def '\n",
       "                                        '__init__(self):\\\\\\\\n          '\n",
       "                                        'super(Net, '\n",
       "                                        'self).__init__()\\\\\\\\n          '\n",
       "                                        'self.fc1 = nn.Linear(784,100) '\n",
       "                                        '\\\\\\\\n          self.relu = '\n",
       "                                        'nn.ReLU()\\\\\\\\n          self.fc2 = '\n",
       "                                        'nn.Linear(100,100) \\\\\\\\n          '\n",
       "                                        'self.fc3 = nn.Linear(100,10) '\n",
       "                                        '\\\\\\\\n\\\\\\\\n      def forward(self, x): '\n",
       "                                        '\\\\\\\\n          x1 = '\n",
       "                                        'self.fc1(x)\\\\\\\\n          x2 = '\n",
       "                                        'self.relu(x1)\\\\\\\\n          x3 = '\n",
       "                                        'self.fc2(x2)\\\\\\\\n          x4 = '\n",
       "                                        'self.relu(x3)\\\\\\\\n          x5 = '\n",
       "                                        'self.fc3(x4)\\\\\\\\n\\\\\\\\n          '\n",
       "                                        'return x5\\\\\\\\n\\\\\\\\n  download_root = '\n",
       "                                        \"'./MNIST_data'\\\\\\\\n\\\\\\\\n  \"\n",
       "                                        'train_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\\\\\n                          '\n",
       "                                        'train=True,\\\\\\\\n                          '\n",
       "                                        'transform=transforms.ToTensor(),\\\\\\\\n                          '\n",
       "                                        'download=True) \\\\\\\\n\\\\\\\\n  '\n",
       "                                        'test_dataset = '\n",
       "                                        'datasets.MNIST(root=download_root,\\\\\\\\n                          '\n",
       "                                        'train=False,\\\\\\\\n                          '\n",
       "                                        'transform=transforms.ToTensor(), '\n",
       "                                        '\\\\\\\\n                          '\n",
       "                                        'download=True) \\\\\\\\n\\\\\\\\n  batch_size '\n",
       "                                        '= 100\\\\\\\\n  train_loader = '\n",
       "                                        'DataLoader(train_dataset, '\n",
       "                                        'batch_size=batch_size, '\n",
       "                                        'shuffle=True)\\\\\\\\n  test_loader = '\n",
       "                                        'DataLoader(test_dataset, '\n",
       "                                        'batch_size=batch_size, shuffle=True) '\n",
       "                                        '\\\\\\\\n\\\\\\\\n  model = Net() \\\\\\\\n  '\n",
       "                                        'loss_function = nn.CrossEntropyLoss() '\n",
       "                                        '\\\\\\\\n\\\\\\\\n  optimizer = '\n",
       "                                        'torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\\\\\\\\n  '\n",
       "                                        'epochs = 1\\\\\\\\n\\\\\\\\n  best_accuracy = '\n",
       "                                        '0\\\\\\\\n  model.zero_grad() \\\\\\\\n\\\\\\\\n  '\n",
       "                                        'for epoch in '\n",
       "                                        'range(epochs):\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'model.train() \\\\\\\\n    train_accuracy '\n",
       "                                        '= 0 \\\\\\\\n    train_loss = 0 '\n",
       "                                        '\\\\\\\\n\\\\\\\\n    for images, labels in '\n",
       "                                        'train_loader:\\\\\\\\n      images = '\n",
       "                                        'images.reshape(batch_size,784)\\\\\\\\n      '\n",
       "                                        'image = model(images)\\\\\\\\n      loss '\n",
       "                                        '= '\n",
       "                                        'loss_function(image,labels)\\\\\\\\n\\\\\\\\n      '\n",
       "                                        'optimizer.zero_grad()\\\\\\\\n      '\n",
       "                                        'loss.backward()\\\\\\\\n      '\n",
       "                                        'optimizer.step()\\\\\\\\n\\\\\\\\n      '\n",
       "                                        'prediction = '\n",
       "                                        'torch.argmax(image,1)\\\\\\\\n      '\n",
       "                                        'correct = (prediction == '\n",
       "                                        'labels)\\\\\\\\n      train_accuracy+= '\n",
       "                                        'correct.sum().item() / '\n",
       "                                        'len(train_dataset)\\\\\\\\n      '\n",
       "                                        'train_loss += loss.item() / '\n",
       "                                        'len(train_loader)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'model.eval() \\\\\\\\n    val_accuracy = '\n",
       "                                        '0 \\\\\\\\n    val_loss = 0 \\\\\\\\n\\\\\\\\n    '\n",
       "                                        'for images,labels in '\n",
       "                                        'test_loader:\\\\\\\\n      images = '\n",
       "                                        'images.reshape(batch_size,784)\\\\\\\\n      '\n",
       "                                        'image = model(images)\\\\\\\\n      loss '\n",
       "                                        '= '\n",
       "                                        'loss_function(image,labels)\\\\\\\\n\\\\\\\\n      '\n",
       "                                        'correct = (torch.argmax(image,1) == '\n",
       "                                        'labels)\\\\\\\\n      val_accuracy += '\n",
       "                                        'correct.sum().item() / '\n",
       "                                        'len(test_dataset)\\\\\\\\n      val_loss '\n",
       "                                        '+= loss.item() / '\n",
       "                                        'len(test_loader)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        \"print(f'epoch: {epoch}/{epochs} \"\n",
       "                                        'train_loss: {train_loss:.5} '\n",
       "                                        'train_accuracy: {train_accuracy:.5} '\n",
       "                                        'val_loss: {val_loss:.5} val_accuracy: '\n",
       "                                        \"{val_accuracy:.5}')\\\\\\\\n\\\\\\\\n    if \"\n",
       "                                        'best_accuracy < val_accuracy: '\n",
       "                                        '\\\\\\\\n      best_accuracy = '\n",
       "                                        'val_accuracy\\\\\\\\n      best_val_loss '\n",
       "                                        '= val_loss\\\\\\\\n      '\n",
       "                                        \"torch.save(model.state_dict(),'./best_model.pt')\\\\\\\\n      \"\n",
       "                                        'print(f\\\\\\\\\\\\\"===========> Save '\n",
       "                                        'Model(Epoch: {epoch}, Accuracy: '\n",
       "                                        '{best_accuracy:.5})\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'print(\\\\\\\\\\\\\"--------------------------------------------------------------------------------------------\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n  '\n",
       "                                        \"metrics = {\\\\\\\\n        'metrics': \"\n",
       "                                        \"[{\\\\\\\\n            'name': \"\n",
       "                                        \"'accuracy-score',\\\\\\\\n            \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'best_accuracy,\\\\\\\\n            '\n",
       "                                        \"'format': \"\n",
       "                                        '\\\\\\\\\\\\\"PERCENTAGE\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        '}]\\\\\\\\n    }\\\\\\\\n\\\\\\\\n  with '\n",
       "                                        \"open('./mlpipeline-metrics.json','w') \"\n",
       "                                        'as f:\\\\\\\\n    '\n",
       "                                        'json.dump(metrics,f)\\\\\\\\n\\\\\\\\n  '\n",
       "                                        'print(\\\\\\\\\\\\\"best_model uploaded to '\n",
       "                                        'pvc!\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train', \"\n",
       "                                        \"description='')\\\\\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= train(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-pytorch:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Train\\\\\"}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\"}}}], \"arguments\": {\"parameters\": '\n",
       "                                        '[]}, \"serviceAccountName\": '\n",
       "                                        '\"pipeline-runner\"}}'},\n",
       " 'resource_references': [{'key': {'id': '27dedf49-c92b-4124-b3ee-90745922498d',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'torch',\n",
       "                          'relationship': 'OWNER'}],\n",
       " 'scheduled_at': datetime.datetime(2023, 1, 9, 13, 53, 59, tzinfo=tzutc()),\n",
       " 'service_account': 'default-editor',\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run_pipeline(experiment_id=experiment.id,job_name=pipeline_name,pipeline_package_path=pipeline_package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "513994c1-e1fa-4a80-ab1d-a3356aa33286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_id = client.get_pipeline_id(pipeline_name)\n",
    "client.delete_pipeline(pipeline_id=pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "07be0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = client.get_experiment(experiment_name=pipeline_name,namespace=NAMESPACE)\n",
    "experiment_id = experiment_info.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e29025f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "5bbbcd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b66d3771-0ca0-4edb-8e6b-6efb7894e813\n",
      "41f0e917-0670-4940-830c-2663560c3bfb\n",
      "be3ff9f3-b609-4439-9363-cef0c5028721\n",
      "93d5ae8b-3922-41c4-aeb8-6f91dba8bde3\n",
      "e4372185-883f-4f0f-88fa-b16058a93ad9\n",
      "4ca37a3e-72a7-45d6-81a7-b65fb3f32838\n",
      "1d07e319-ab1e-47a9-8673-e4dce9631ff6\n",
      "faa4817f-5bfa-4943-bb89-6b3323875a54\n",
      "198b0ea4-a80c-45e6-a19d-e6610f0dd883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(client.list_runs().total_size):\n",
    "    run_id = client.list_runs().runs[i].id\n",
    "    delete_run_id = run_id\n",
    "    print(delete_run_id)\n",
    "\n",
    "client.runs.delete_run(id=delete_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a519d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
